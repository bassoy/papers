

\begin{figure*}[t]
\input{fig.performance.tlib.contour-mkl-parloop}
\input{fig.performance.tlib.contour-mkl-pargemm} 
\caption{%
\footnotesize %
Performance contour plots in double-precision GFLOPS/core of the proposed TTM algorithms \tf{<par-loop>} and \tf{<par-gemm>} with varying tensor orders $p$ and contraction modes $q$. 
The top row of maps (1x) depict measurements of the \tf{<par-loop>} versions while the bottom row of maps with number (2x) contain measurements of the \tf{<par-gemm>} versions.
Tensors are asymmetrically shaped on the left four maps (a,b) and symmetrically shaped on the right four maps (c,d).
Tensor $\mubA$ and $\mubC$ have the first-order while matrix $\mbB$ has the row-major ordering.
All functions have been measured on an Intel Xeon Gold 5318Y.
\label{fig:performance.tlib.contour}
}
\end{figure*}


\begin{figure*}[t]
\input{fig.performance.tlib.case8-cdf-mkl}
\input{fig.performance.tlib.case8-cdf-aocl}
\caption{ %
\footnotesize%
Cumulative performance distributions in double-precision GFLOPS/core of the proposed algorithms for the eighth case.
Each distribution belongs to one algorithm:
\tf{<batched-gemm>} (\ref{coord:gemm_batch}), %
\tf{<combined>} (\ref{coord:optimized}),
\tf{<par-gemm,slice>} (\ref{coord:seq_loops_par_gemm_slice}) and
\tf{<par-loop,slice>} (\ref{coord:par_loops_seq_gemm_slice}),
\tf{<par-gemm,subtensor>} (\ref{coord:seq_loops_par_gemm_subtensor}) and
\tf{<par-loop,subtensor>} (\ref{coord:par_loops_seq_gemm_subtensor}).
The top row of maps (1x) depict measurements performed on an Intel Xeon Gold 5318Y with the MKL while the bottom row of maps with number (2x) contain measurements performed on an AMD EPYC 9354 with the AOCL.
Tensors are asymmetrically shaped in (a) and (b) and symmetrically shaped in (c) and (d).
Input matrix has the row-major ordering (rm) in (a) and (c) and column-major ordering (cm) in (b) and (d).
}
\label{fig:performance.tlib.case8}
\end{figure*}


\begin{figure*}[t]
\input{fig.performance.tlib.format.mkl}
\input{fig.performance.tlib.format.aocl}
%\input{fig.performance.tlib.format}
\caption{ %
\footnotesize%
Box plots visualizing performance statics in double-precision GFLOPS/core of the function with row-major (left) or column-major matrices (right).
Box plot number $k$ denotes the $k$-order tensor layout of symmetrically shaped tensors with order $7$.
% where the $1$-order and $7$-order layouts are the first- and last-order storage formats, respectively.
}
\label{fig:performance.tlib.format}
\end{figure*}

\begin{figure*}[t]
\input{fig.performance.comparison-mkl}
\input{fig.performance.comparison-aocl} 
\caption{ %
\footnotesize%
Cumulative performance distributions of TTM implementations in double-precision GFLOPS/core.
Each distribution corresponds to a library:
\textbf{TLIB}[ours] (\ref{coord:nonsymmetric.tlib.slice}), %
\textbf{TCL} (\ref{coord:nonsymmetric.tcl}), %
\textbf{TBLIS} (\ref{coord:nonsymmetric.tblis}), %
\textbf{LibTorch} (\ref{coord:nonsymmetric.libtorch}), %
\textbf{Eigen} (\ref{coord:nonsymmetric.eigen}),
\textbf{TuckerMPI} (\ref{coord:symmetric.tuckermpi}).
Libraries have been tested with asymmetrically-shaped (left plot) and symmetrically-shaped tensors (right plot).
}
\label{fig:performance.comparison}
\end{figure*}

\begin{table*}[t]
\input{tab.performance.comparison-mkl-aocl.summary}
\caption%
{%
\footnotesize
The table presents the minimum, median, and maximum runtime performances in GFLOPS/core alongside the median speedup of TLIB compared to other libraries.
The tests were conducted on an Intel Xeon Gold 5318Y CPU (left) and an AMD EPYC 9354 CPU (right). 
The performance values on the upper and lower rows of one table were evaluated using asymmetrically and symmetrically shaped tensors, respectively. 
}
\label{tab:comparison}
\end{table*}



\begin{figure*}[t]
\input{fig.performance-sdr.comparison-mkl}
\input{fig.performance-sdr.comparison-aocl}
\caption%
{%
\footnotesize
Bar plots contain median runtime in seconds of %
\tf{TLIB} (\ref{coord:bar.tlib_optimized.mkl}), %
\tf{TCL} (\ref{coord:bar.tcl.mkl}), %
\tf{TBLIS} (\ref{coord:bar.tblis.mkl}), %
\tf{LibTorch} (\ref{coord:bar.torch.mkl}), %
\tf{Eigen} (\ref{coord:bar.eigen.mkl}) and %
\tf{TuckerMPI} (\ref{coord:bar.tucker.mkl}). 
The tests were conducted on an Intel Xeon Gold 5318Y CPU (top) and an AMD EPYC 9354 CPU (bottom) using order-3 and order-4 tensors with shapes that are described in Table \ref{tab:dataset}. 
%The performance values on the upper and lower rows of one table were evaluated using asymmetrically and symmetrically shaped tensors, respectively. 
}
\label{fig:performance-sdr.comparison}
\end{figure*}



\section{Experimental Results and Discussion}
\label{sec:results}


\subsection{Slicing Methods}
\label{subsec:results.slicing-methods}
This section analyzes the performance of the two proposed slicing methods \ttt{<slice>} and \ttt{<subtensor>} that have been discussed in section \ref{subsec:parallel.multi-loops}.
%Note that this analysis is equal to minimizing or maximizing the input parameter $M_C$.
Fig. \ref{fig:performance.tlib.contour} contains eight performance contour plots of four \ttt{ttm} functions \ttt{<par-loop>} and \ttt{<par-gemm>}.
Both functinos either compute the slice-matrix product with subtensors \ttt{<subtensor>} or tensor slices \ttt{<slice>} on the Intel Xeon Gold 5318Y CPU.
Each contour level within the plots represents a mean GFLOPS/core value that is averaged across tensor sizes.

Every contour plot contains all applicable TTM cases listed in Table \ref{tab:mapping_rm_cm}.
The first column of performance values is generated by \ttt{gemm} belonging to the TTM case $3$, except the first element which corresponds to TTM case $2$.
The first row, excluding the first element, is generated by TTM case $6$ function.
TTM case $7$ is covered by the diagonal line of performance values when $q = p$.  
Although Fig. \ref{fig:performance.tlib.contour} suggests that $q>p$ is possible, our profiling program ensures that $q=p$.
TTM case $8$ with multiple \ttt{gemm} calls is represented by the triangular region which is defined by $1<q<p$.


% With <par-loop,seq-gemm>
% Asymmetrically Shaped Tensors
Function \ttt{<par-loop,slice>} runs on average with $34.96$ GFLOPS/core ($1.67$ TFLOPS) with asymmetrically shaped tensors.
With a maximum performance of $57.805$ GFLOPS/core ($2.77$ TFLOPS), it performs on average $89.64$\% faster than \ttt{<par-loop,subtensor>}.
The slowdown with subtensors at $q=p-1$ or $q=p-2$ can be explained by the small loop count of the function that are $2$ and $4$, respectively.
While function \ttt{<par-loop,slice>} is affected by the tensor shapes for dimensions $p=3$ and $p=4$ as well, its performance improves with increasing order due to the increasing loop count.
%The performance drops and their corresponding locations on the performance plots have also been mentioned in \cite{bassoy:2024:ttm}.
%Symmetrically Shaped Tensors
Function \ttt{<par-loop,slice>} achieves on average $17.34$ GFLOPS/core ($832.42$ GFLOPS) if symmetrically shaped tensors are used.
If subtensors are used, function \ttt{<par-loop,subtensor>} achieves a mean throughput of $17.62$ GFLOPS/core ($846.16$ GFLOPS) and is on average $9.89$\% faster than \ttt{<par-loop,slice>}.
The performances of both functions are monotonically decreasing with increasing tensor order, see plots (1.c) and (1.d) in Fig. \ref{fig:performance.tlib.contour}.
%The average performance decrease of both functions can be approximated by a cubic polynomial with the coefficients $-35$, $640$, $-3848$ and $8011$.
%The performance behavior with symmetrically shaped tensors has also been described in \cite{bassoy:2024:ttm}.


% With <seq-loop,par-gemm>
% Asymmetrically Shaped Tensors
Function \ttt{<par-gemm,slice>} averages $36.42$ GFLOPS/core ($1.74$ TFLOPS) and achieves up to $57.91$ GFLOPS/core ($2.77$ TFLOPS) with asymmetrically shaped tensors.
Using subtensors, function \ttt{<par-gemm,subtensor>} exhibits almost identical performance characteristics and is on average $3.42$\% slower than its counterpart with tensor slices.
% Symmetrically Shaped Tensors
For symmetrically shaped tensors, \ttt{<par-gemm>} with subtensors and tensor slices achieve a mean throughput $15.98$ GFLOPS/core ($767.31$ GFLOPS) and $15.43$ GFLOPS/core ($740.67$ GFLOPS), respectively.
However, function \ttt{<par-gemm,subtensor>} is on average $87.74$\% faster than \ttt{<par-gemm,slice>} which is hardly visible due to small performance values around $5$ GFLOPS/core or less whenever $q<p$ and the dimensions are smaller than $256$.
The speedup of the \ttt{<subtensor>} version can be explained by the smaller loop count and slice-matrix multiplications with larger tensor slices.

Our findings indicate that, regardless of the parallelization method employed, subtensors are most effective with symmetrically shaped tensors, whereas tensor slices are preferable with asymmetrically shaped tensors when both the contraction mode and leading dimension are large.



\subsection{Parallelization Methods}
\label{subsec:results.parallelization-methods}
This subsection compares the performance results of the two parallelization methods, \ttt{<par-gemm>} and \ttt{<par-loop>}, as introduced in Section \ref{subsec:parallel.multi-loops} and illustrated in Fig. \ref{fig:performance.tlib.contour}.

% Asymmetrically shaped tensors
With asymmetrically shaped tensors, both \ttt{<par-gemm>} functions with subtensors and tensor slices compute the tensor-matrix product on average with ca. $36$ GFLOPS/core and outperform function \ttt{<par-loop,subtensor>} on average by a factor of $2.31$.
The speedup can be explained by the performance drop of function \ttt{<par-loop,subtensor>} to $3.49$ GFLOPS/core at $q=p-1$ while both versions of \ttt{<par-gemm>} operate around $39$ GFLOPS/core.
Function \ttt{<par-loop,slice>} performs better for reasons explained in the previous subsection.
However, it is on average $30.57$\% slower than function \ttt{<par-gemm,slice>} due to the aforementioned performance drops.

% Symmetrically shaped tensors
In case of symmetrically shaped tensors, \ttt{<par-loop>} with subtensors and tensor slices outperform their corresponding \ttt{<par-gemm>} counterparts by $23.3$\% and $32.9$\%, respectively.
The speedup mostly occurs when $1<q<p$ where the performance gain is a factor of $2.23$.
This performance behavior can be expected as the tensor slice sizes decreases for the eighth case with increasing tensor order causing the parallel slice-matrix multiplication to perform on smaller matrices.
In contrast, \ttt{<par-loop>} can execute small single-threaded slice-matrix multiplications in parallel.

In summary, function \ttt{<par-loop,subtensor>} with symmetrically shaped tensors performs best.
If the leading and contraction dimensions are large, both versions of function \ttt{<par-gemm>} outperform \ttt{<par-loop>} with any type of slicing. 

\subsection{LoG Variants}
\label{subsec:results.log}
The contour plots in Fig. \ref{fig:performance.tlib.contour} contain performance data that are generated by all applicable TTM cases of each \ttt{ttm} function.
Yet, the presented slicing or parallelization methods only affect the eighth case, while all other TTM cases apply a single multi-threaded \ttt{gemm} with the same configuration.
The following analysis will consider performance values of the eighth case in order to have a more fine grained visualization and discussion of the loops over \ttt{gemm} implementations.
Fig. \ref{fig:performance.tlib.case8} contains cumulative performance distributions of all the proposed algorithms including the functions \ttt{<batched-gemm>} and \ttt{<combined>} for the eighth TTM case only.
Moreover, the experiments have been additionally executed on the AMD EPYC processor and with the column-major ordering of the input matrix as well.

%Explain what cumulate performance distribution means.
The probability $x$ of a point $(x,y)$ of a distribution function for a given algorithm corresponds to the number of test instances for which that algorithm that achieves a throughput of either $y$ or less.
For instance, function \ttt{<batched-gemm>} computes the tensor-matrix product with asymmetrically shaped tensors in $25$\% of the tensor instances with equal to or less than $10$ GFLOPS/core.
%Consequently, distribution functions with a logarithmic growth are favorable while exponential behavior is less desirable.
Please note that the four plots on the right, plots (c) and (d), have a logarithmic y-axis for a better visualization.


\subsubsection{Combined Algorithm and Batched GEMM}
% can you refer to what figure you are referring to ?
This subsection discusses the performance of function \ttt{<batched-gemm>} and \ttt{<combined>} against those of \ttt{<par-loop>} and \ttt{<par-gemm>} for the eighth TTM case.

Given a row-major matrix ordering, the combined function \ttt{<combined>} achieves on the Intel processor a median throughput of $36.15$ and $4.28$ GFLOPS/core with asymmetrically and symmetrically shaped tensors.
Reaching up to $46.96$ and $45.68$ GFLOPS/core, it is on par with \ttt{<par-gemm,subtensor>} and \ttt{<par-loop,slice>} and outperforms them for some tensor instances.
Note that both functions run significantly slower either with asymmetrically or symmetrically shaped tensors.
The observable superior performance distribution of \ttt{<combined>} can be attributed to the heuristic which switches between \ttt{<par-loop>} and \ttt{<par-gemm>} depending on the inner and outer loop count as explained in section \ref{subsec:parallel.multi-loops}.

Function \ttt{<batched-gemm>} of the BLAS-like extension library has a performance distribution that is akin to the \ttt{<par-loop,subtensor>}.
In case of asymmetrically shaped tensors, all functions except \ttt{<par-loop,subtensor>} outperform \ttt{<batched-gemm>} on average by a factor of $2.57$ and up to a factor $4$ for $2 \leq q\leq5$ with $q+2 \leq p \leq q+5$. %q+2=p and q+5=p 
In contrast, \ttt{<par-loop,subtensor>} and \ttt{<batched-gemm>} show a similar performance behavior in the plot (1c) and (1d) for symmetrically shaped tensors, running on average $3.55$ and $8.38$ times faster than \ttt{<par-gemm>} with subtensors and tensor slices, respectively.
%Function \ttt{<par-loop,slice>} underperforms for $p>3$, i.e. when the tensor dimensions are less than $64$. % <- Don't know if I need this.
%TODO:These observations have also been mentioned in \cite{bassoy:2024:ttm}.

In summary, \ttt{<combined>} performs as fast as, or faster than, \ttt{<par-gemm,subtensor>} and \ttt{<par-loop,slice>}, depending on the tensor shape. 
Conversely, \ttt{<batched-gemm>} underperforms for asymmetrically shaped tensors with large contraction modes and leading dimensions.

\subsubsection{Matrix Formats}
This subsection discusses if the input matrix storage formats have any affect on the runtime performance of the proposed functions.
The cumulative performance distributions in Fig. \ref{fig:performance.tlib.case8} suggest that the storage format of the input matrix has only a minor impact on the performance.
The Euclidean distance between normalized row-major and column-major performance values is around $5$ or less with a maximum dissimilarity of $11.61$ or $16.97$, indicating a moderate similarity between the corresponding row-major and column-major data sets.
Moreover, their respective median values with their first and third quartiles differ by less than $5$\% with three exceptions where the difference of the median values is between $10$\% and $15$\%.
% for function \ttt{combined} with symmetrically shaped tensors on both processors.


\subsubsection{BLAS Libraries}
This subsection compares the performance of functions that use Intel's Math Kernel Library (MKL) on the Intel Xeon Gold 5318Y processor with those that use the AMD Optimizing CPU Libraries (AOCL) on the AMD EPYC 9354 processor. 
Comparing the performance per core and limiting the runtime evaluation to the eighth case, MKL-based functions with asymmetrically shaped tensors run on average between $1.48$ and $2.43$ times faster than those with the AOCL.
For symmetrically shaped tensors, MKL-based functions are between $1.93$ and $5.21$ times faster than those with the AOCL.
In general, MKL-based functions on the respective CPU achieve a speedup of at least $1.76$ and $1.71$ compared to their AOCL-based counterpart when asymmetrically and symmetrically shaped tensors are used.

%TODO: can you tell at which cases the performance drops?


\subsection{Tensor Layouts}
Fig. \ref{fig:performance.tlib.format} contains four box plots summarizing the performance distribution of the \ttt{<combined>} function using the AOCL and MKL.
%visualizing double-precision performance statics in double-precision TFLOPS of \tf{<gemm\_batch>} (left subfigure) and \tf{<par-loops,seq-gemm>} with subtensors (right subfigure).
Every $k$-th box plot has been computed from benchmark data with symmetrically shaped order-$7$ tensors that has a $k$-order tensor layout.
The $1$-order and $7$-order layout, for instance, are the first-order and last-order storage formats of an order-$7$ tensor.
%Note that function \ttt{<combined>} only calls \ttt{<par-loop,subtensor>}.

The reduced performance of around $1$ and $2$ GFLOPS can be attributed to the fact that contraction and leading dimensions of symmetrically shaped subtensors are at most $48$ and $8$, respectively.
When \ttt{<combined>} is used with MKL, the relative standard deviations (RSD) of its median performances are $2.51$\% and $0.74$\%, with respect to the row-major and column-major formats.
The RSD of its respective interquartile ranges (IQR) are $4.29$\% and $6.9$\%, indicating a similar performance distributions.
Using \ttt{<combined>} with AOCL, the RSD of its median performances for the row-major and column-major formats are $25.62$\% and $20.66$\%, respectively.
The RSD of its respective IQRs are $10.83$\% and $4.31$\%, indicating a similar performance distributions.
A similar performance behavior can be observed also for other \ttt{ttm} variants such as \ttt{<par-loop,slice>}.
The runtime results demonstrate that the function performances stay within an acceptable range independent for different $k$-order tensor layouts and show that our proposed algorithms are not designed for a specific tensor layout.






\subsection{Comparison with Related Work}
This subsection compares our best performing algorithm with libraries that do not use the LoG approach.
\tbf{TCL} implements the TTGT approach with a high-perform tensor-transpose library \tbf{HPTT} which is discussed in \cite{springer:2018:design}.
TCL has been used with the same BLAS libraries as TLIB to ensure a fair comparison.
\tbf{TBLIS} (v1.2.0) implements the GETT approach that is akin to BLIS' algorithm design for the matrix multiplication \cite{matthews:2018:high}.
The library has been compiled with the \ttt{zen4} and \ttt{skx-2} to enable architecture specific optimization.
%TODO: add footnote that is required to enable support for zen4 and skx-2 
The tensor extension of \tbf{Eigen} (v3.4.90) is used by the Tensorflow framework.
Library \tbf{LibTorch} (v2.5.0) is the C++ distribution of PyTorch \cite{paszke:2019:pytorch}.
The \tbf{TuckerMPI} library is a parallel C++ software package for large-scale data compression which provides a local and distributed TTM function \cite{ballard:2020:tuckermpi}.
The local version implements the LoG approach using a BLAS implementation and computes the TTM product similar to our function \ttt{<par-gemm,subtensor>}.
Note that we were use the current TuckerMPI version with Intel's MKL, which is why TuckerMPI's TTM has only been executed on the Intel CPU.
\tbf{TLIB} denotes our library and the previously discussed \ttt{<combined>} algorithm.
If not otherwise stated, all of the following performance and comparisons numbers represent medians across the entire tensor set.

%We will use performance or percentage tuples of the form (TCL, TBLIS, LibTorch, Eigen) where each tuple element denotes the performance or runtime percentage of a particular library.
\subsubsection{Artificial Tensor Shapes}
Fig. \ref{fig:performance.tlib.case8} compares the performance distribution of our implementation with the previously mentioned libraries.
Using MKL on the Intel CPU, TLIB achieves a performance of $38.21$ GFLOPS/core ($1.83$ TFLOPS) and reaches with asymmetrically shaped tensors at most $57.68$ GFLOPS/core ($2.76$ TFLOPS), given the the shape sets $N_k$ with $1 \leq k \leq 10$.
TLIB is in at least $2.03$x as many tensor instances faster than other libraries and achieves a speedup of at least $6.36$\%.
LibTorch and TuckerMPI have almost the same performance of $38.17$ and $35.98$ GFLOPS/core, yet only reach a peak performance $50.48$ and $53.21$ GFLOPS/core.
Both are $17.47$\% and $6.97$\% slower than TLIB.
In case of symmetrically shaped tensors from the shape set $M$, TLIB's computes the TTM with $8.99$ GFLOPS/core ($431.52$ GFLOPS).
Except for TBLIS, TLIB achieves a speedup for at least $33$\% more tensor instances and is at least $3.08$\% faster.
Moreover, TLIB achieves a median speedup of $12.98$\% and $6.23$\% compared to LibTorch and TuckerMPI.
With a higher performance of $9.73$ GFLOPS/core, TBLIS is faster than TLIB for about the same amount of tensor instances and is $1.38$\% slower than TLIB.

On the AMD CPU, TLIB computes the tensor product with $24.28$ GFLOPS/core ($1.55$ TFLOPS), reaching with asymmetrically shaped tensors a maximum performance of $50.18$ GFLOPS/core ($3.21$ TFLOPS).
TBLIS and TCL execute the TTM with $26.81$ and $24.11$ GFLOPS/core, executing the TTM equally fast as TLIB with a speedup percentage of $0.57$ and $0.43$.
Moreover, TLIB is faster than TBLIS and TCL in the same number of tensor instances as in the opposite case.
The three libraries are $29.68$\% and a factor of $2.17$ faster than LibTorch and Eigen, respectively.
In case of symmetrically shaped tensors, TLIB has a median performance of $7.52$ GFLOPS/core ($481.39$ GFLOPS).
Compared to the second-fastest library TCL, TLIB speeds up the computation by $6.10$\% and is in $43.66$\% more tensor instances faster than TCL.
TBLIS, LibTorch and Eigen are outperformed by TLIB by at least $12.37$\%.

In most instances, TLIB is able to outperform other libraries across all TTM cases with few exceptions.
On the AMD CPU, TCL achieves a higher throughput of about $9$\% for the second and third TTM cases when asymmetrically shaped tensors are used.
TBLIS is $12.63$\% faster than TLIB for the eighth TTM case with the same tensor set.
On the Intel CPU, LibTorch is in the $7$th TTM case $16.94$\% faster than TLIB.
The TCL library runs on average as fast as TLIB in the $6$th and $7$th TTM cases .
The performances of TLIB, TBLIS and TuckerMPI in the $8$th TTM case are almost on par, TLIB executing the TTM about $3.2$\% faster.
In case of symmetrically shaped tensors, TBLIS and LibTorch outperform TLIB in the $7$th TTM case by $38.5$\% and $219.5$\%.


\subsubsection{Real-World Tensor Shapes}
We have additionally conducted performance tests with an order-$3$ and seven order-$4$ tensors that have also been used in SDRBench \cite{zhao:2020:sdrbench}.
The corresponding tensor shape set $Q$ and the tensor shapes are given in Table \ref{tab:dataset}.
With a maximum tensor order of $4$, every tensor is multiplied with a matrix along every mode using a TTM implementation.
Note that the multiplication over the first and fourth mode corresponds to the sixth and seventh TTM case in Table \ref{tab:mapping_rm_cm} for which TLIB will call a single \ttt{gemm}.
The multiplication over the second and third mode corresponds to the eighth TTM case where a \ttt{gemm} is called multiple times.

Fig. \ref{fig:performance-sdr.comparison} contains bar plots for all tensor shapes of set $Q$.
The size of each bar is the total running time of the respective TTM implementation over all modes that is executed on an Intel Xeon Gold 5318Y CPU and an AMD EPYC 9354 CPU.
Note that TCL was not able to compute the TTM for the EXAFEL data set which is why the runtime is set to zero.

On the Intel Xeon Gold 5318Y CPU, TLIB is for most tensor instances faster and reaches a maximum speedup of $137.32$\% (TCL), $100.80$\% (TBLIS), $210.71$\% (LibTorch), $798.91$\% (Eigen), $581.73$\% (TuckerMPI).
TCL is on par with TLIB for the CESM-ATM data set.
TuckerMPI is for the CESM-ATM and Miranda data sets $46.8$\% and $13.7$\% faster than TLIB 
The TTMs of TuckerMPI and LibTorch compute the tensor product for the fourth mode faster than TLIB, independent of the tensor instance.

On the AMD EPYC 9354 CPU, TLIB performs better than most other libraries except for TCL and LibTorch in some instances.
TLIB reaches a maximum speedup of $33.36$\% (TCL), $117.22$\% (TBLIS), $221.25$\% (LibTorch), $205.80$\% (Eigen).
TCL outerperforms TLIB by $16.22$\% (NYX) and $71.65$\% (Miranda).
In this case, TCL computes the tensor product over the fourth mode for almost all tensor instances faster than TLIB.
In case of the SCALE-LETKF data set TCL is $3.4$x faster.
LibTorch outperforms TLIB for the CESM-ATM data set by $42.02$\%.
%In that case, LibTorch is outperforming $67$\% when computing the tensor product over mode one.

The runtime tests with tensors from the SDRBench demonstrates that for most tensor instances with real-world tensor shapes, TLIB is able to compute the tensor product faster than other libraries.


\subsection{Summary}
We have evaluated the impact of performing the \ttt{gemm} function with subtensors and tensor slices.
Our findings indicate that, subtensors are most effective with symmetrically shaped tensors independent of the parallelization method. 
Tensor slices are preferable with asymmetrically shaped tensors when both the contraction mode and leading dimension are large.
Our runtime results show that parallel executed single-threaded \ttt{gemm} performs best with symmetrically shaped tensors.
If the leading and contraction dimensions are large, functions with a multi-threaded \ttt{gemm} outperforms those with a single-threaded \ttt{gemm} for any type of slicing.
We have also shown that our \ttt{<combined>} performs in most cases as fast as \ttt{<par-gemm,subtensor>} and \ttt{<par-loop,slice>}, depending on the tensor shape.
Function \ttt{<batched-gemm>} is less efficient in case of asymmetrically shaped tensors with large contraction and leading dimensions.
While matrix storage formats have only a minor impact on TTM performance, runtime measurements show that a TTM using MKL on the Intel Xeon Gold 5318Y CPU achieves higher per-core performance than a TTM with AOCL on the AMD EPYC 9354 processor.
We have also demonstrated that our algorithms perform consistently well across different $k$-order tensor layouts, indicating that they are layout-oblivious and do not depend on a specific tensor format.
Our runtime tests show that TLIB'S function \ttt{<combined>} is, in median, between $15.38$\% and $257.58$\% faster than other competing libraries, except for TBLIS.
TLIB is either on par with or slightly outperforms TBLIS for many tensor shapes which uses optimized kernels for the TTM computation.
Table \ref{tab:comparison} contains the minimum, median, and maximum runtime performances including TLIB's speedups for the whole tensor test sets.

%TODO: explain the shortcommings of the comparisons.
%TODO: correct the summary depending on the output of the previous section
%TODO: integrate the SDRBench.

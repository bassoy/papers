\section{Algorithm Design}
\label{sec:design}
\subsection{Baseline Algorithm with Contiguous Memory Access}
\label{sec:design:modified.baseline.algorithm}
The tensor-matrix multiplication (TTM) in equation \ref{equ:tensor.matrix.multplication} can be implemented with a single algorithm using nested recursion \cite{bassoy:2018:fast}.
Such an algorithm consists of two \ttt{if} statements with recursive calls and an \ttt{else} branch which constitutes the base case.
A naive implementation recursively selects fibers of the input and output tensor for the base case that computes a fiber-matrix product.
The outer loop iterates over the dimension $m$ and selects an element of $\mubC$'s fiber and a row of $\mbB$. 
The inner loop then iterates over dimension $n_q$ and computes the inner product of a fiber of $\mubA$ and the row $\mbB$. 
In this case, elements of $\mubA$ and $\mubC$ are accessed non-contiguously whenever $\pi_1 \neq q$ and matrix $\mbB$ is accessed only with unit strides 
if it elements are stored contiguously along its rows.
%The access pattern can be improved by reordering tensor elements according to the storage format.
%However, copy operations reduce the overall throughput of the operation, see \cite{shi:2016:tensor.contraction}.

A better approach is illustrated by Algorithm~\ref{alg:ttm.sequential.coalesced} where the loop order is adjusted to the tensor layout $\mbpi$ and memory is accessed contiguously for $\pi_1 \neq q$ and $p > 1$.
The algorithm takes the input order-$p$ tensor $\mubA$, input matrix $\mbB$, order-$p$ output tensor $\mubC$, the shape tuple $\mbn$ of $\mubA$, the layout tuple $\mbpi$ of both tensors, an index tuple $\mbpi$ of length $p$, the first dimension $m$ of $\mbB$, the contraction mode $q$ with $1 \leq q \leq p$ and $\mhq=\mbpi^{-1}(q)$.
Initially called with $\mbi = \mathbf{0}$ and $r=p$, the algorithm increments indices with smaller strides as $w_{\pi_r} \leq w_{\pi_{r+1}}$ with increasing recursion level and decreasing $r$. 
This is accomplished in line 5 which uses the layout tuple $\mbpi$ to select a multi-index element $i_{\pi_r}$ and to increment it with the corresponding stride $w_{\pi_r}$.
The two \ttt{if} statements in line number 2 and 4 allow the loops over modes $q$ and $\pi_1$ to be placed into the base case in which a slice-matrix multiplication is performed.
The inner-most loop of the base case increments $i_{\pi_1}$ with a unit stride and contiguously accesses tensor elements of $\mubA$ and $\mubC$.
The second loop increments $i_q$ with which elements of $\mbB$ are contiguously accessed if $\mbB$ is stored in the row-major format.
The third loop increments $j$ and could be placed as the second loop if $\mbB$ is stored in the column-major format.

\begin{algorithm}[t]
%\SetAlgoNoLine
\DontPrintSemicolon
\SetKwProg{Fn}{}{}{end}
\SetKwFunction{function}{ttm}%
%\SetAlgoNoEnd
\footnotesize 
\SetAlgoVlined
\hrule
\BlankLine
\Fn{\function{$\mubA, \mbB, \mubC, \mbn, \mbpi, \mbi, m, q, \mhq, r$}}
{
	\uIf{$r = \mhq$ }
	{
		\function{$\mubA, \mbB, \mubC, \mbn, \mbpi, \mbi, m, q, \mhq, r-1$ }
	}
	\uElseIf{$r > 1$ }
	{
		\For{$i_{\pi_r} \leftarrow 1$ \KwTo $ n_{\pi_r}$}
		{
			\function{$\mubA, \mbB, \mubC, \mbn, \mbpi, \mbi, m, q, \mhq, r-1$}\;
		}		
	}	
	\Else%{$r\geq1 \wedge m \neq 1$}
	{
		\For{$j \leftarrow 1$ \KwTo $m$}
		{
			\For{$i_q \leftarrow 1$ \KwTo $n_q$}
			{			
				\For{$i_{\pi_1} \leftarrow 1$ \KwTo $n_{\pi_1}$}
				{
					$\mubC([\mbi_1,j,\mbi_2])$ \ttt{+=} $\mubA([\mbi_1,i_q,\mbi_2]) \cdot \mbB(j,i_q)$\;
				}
			}
		}
	}
}
\BlankLine
\hrule
\caption{
\footnotesize %
Modified baseline algorithm for TTM with contiguous memory access.
The tensor order $p$ must be greater than $1$ and the contraction mode $q$ must satisfy $1 \leq q \leq p$ and $\pi_1 \neq q$.
The initial call must happen with $r=p$ where $\mbn$ is the shape tuple of $\mubA$ and $m$ is the $q$-th dimension of $\mubC$. 
Iteration along mode $q$ with $\mhq = \mbpi^{-1}_q$ is moved into the inner-most recursion level.
\label{alg:ttm.sequential.coalesced}
}
\end{algorithm}

While spatial data locality is improved by adjusting the loop ordering, slices $\mubA_{\pi_1,q}'$, fibers $\mubC_{\pi_1}'$ and elements $\mubB(j,i_q)$ are accessed $m$, $n_q$ and $n_{\pi_1}$ times, respectively.
While the specified fiber of $\mubC$ might fit into first or second level cache, slice elements of $\mubA$ are unlikely to fit in the local caches if the slice size $n_{\pi_1} \times n_q$ is large, leading to higher cache misses and suboptimal performance.
Instead of attempting to improve the temporal data locality, we call high-performance BLAS implementations in the base case.
The following subsection explains this approach.

\subsection{BLAS-based Algorithms with Tensor Slices}
\label{sec:design:blas.based.algorithm.slices}
%\vspace{-0.3em}
\begin{table*}[t]
%\captionsetup{width=0.7\textheight}
\centering
\footnotesize
%\scriptsize
\begin{tabular}{ c c c c c c c c c c c c c c c } % 
\toprule
Case & Order $p$ & Layout $\mbpi_{\mubA,\mubC}$ & Layout $\mbpi_{\mbB}$ & Mode $q$ & Routine & \tf{T} & \tf{M} & \tf{N} & \tf{K} & \tf{A} & \tf{LDA} & \tf{B} & \tf{LDB} & \tf{LDC} \\
\midrule
1 & $1$ & -       & \tf{rm/cm} & $1$   & \tf{gemv} & -       & $m$   & $n_1$ & -     & $\mbB$  & $n_1$ & $\mubA$  & - & - \\
\midrule
2 & $2$ & \tf{cm} & \tf{rm} & $1$      & \tf{gemm} & $\mbB$  & $n_2$ & $m$   & $n_1$ & $\mubA$ & $n_1$ & $\mbB$   & $n_1$ & $m$   \\
  & $2$ & \tf{cm} & \tf{cm} & $1$      & \tf{gemm} & -       & $m$   & $n_2$ & $n_1$ & $\mbB$  & $m$   & $\mubA$  & $n_1$ & $m$   \\
3 & $2$ & \tf{cm} & \tf{rm} & $2$      & \tf{gemm} & -       & $m$   & $n_1$ & $n_2$ & $\mbB$  & $n_2$ & $\mubA$  & $n_1$ & $n_1$ \\
  & $2$ & \tf{cm} & \tf{cm} & $2$      & \tf{gemm} & $\mbB$  & $n_1$ & $m$   & $n_2$ & $\mubA$ & $n_1$ & $\mbB$   & $m$   & $n_1$ \\  
4 & $2$ & \tf{rm} & \tf{rm} & $1$      & \tf{gemm} & -       & $m$   & $n_2$ & $n_1$ & $\mbB$  & $n_1$ & $\mubA$  & $n_2$ & $n_2$ \\
  & $2$ & \tf{rm} & \tf{cm} & $1$      & \tf{gemm} & $\mbB$  & $n_2$ & $m$   & $n_1$ & $\mubA$ & $n_2$ & $\mbB$   & $m$   & $n_2$ \\
5 & $2$ & \tf{rm} & \tf{rm} & $2$      & \tf{gemm} & $\mbB$  & $n_1$ & $m$   & $n_2$ & $\mubA$ & $n_2$ & $\mbB$   & $n_2$ & $m$   \\
  & $2$ & \tf{rm} & \tf{cm} & $2$      & \tf{gemm} & -       & $m$   & $n_1$ & $n_2$ & $\mbB$  & $m$   & $\mubA$  & $n_2$ & $m$   \\
\midrule
6 & $>2$ & any    & \tf{rm} & $\pi_1$  & \tf{gemm} & $\mbB$  & $\mbnq$ & $m$     & $n_q$ & $\mubA$ & $n_q$   & $\mbB$  & $n_q$   & $m$\\
  & $>2$ & any    & \tf{cm} & $\pi_1$  & \tf{gemm} & -       & $m$     & $\mbnq$ & $n_q$ & $\mbB$  & $m$     & $\mubA$ & $n_q$   & $m$\\
7 & $>2$ & any    & \tf{rm} & $\pi_p$  & \tf{gemm} & -       & $m$     & $\mbnq$ & $n_q$ & $\mbB$  & $n_q$   & $\mubA$ & $\mbnq$ & $\mbnq$ \\
  & $>2$ & any    & \tf{cm} & $\pi_p$  & \tf{gemm} & $\mbB$  & $\mbnq$ & $m$     & $n_q$ & $\mubA$ & $\mbnq$ & $\mbB$  & $m$     & $\mbnq$ \\
\midrule
8 & $>2$ & any    & \tf{rm} & $\pi_2,..,\pi_{p-1}$ & \tf{gemm*} & -      & $m$ & $n_{\pi_1}$ & $n_q$ & $\mbB$  & $n_q$ & $\mubA$ & $w_q$ & $w_q$ \\
  & $>2$ & any    & \tf{cm} & $\pi_2,..,\pi_{p-1}$ & \tf{gemm*} & $\mbB$ & $n_{\pi_1}$ & $m$ & $n_q$ & $\mubA$ & $w_q$ & $\mbB$  & $m$   & $w_q$ \\
\bottomrule
\end{tabular}
%\vspace{0.2cm}
\caption%
{%
\footnotesize
Eight TTM cases implementing the mode-$q$ TTM with the \tf{gemm} and \tf{gemv} CBLAS functions.
Arguments of \tf{gemv} and \tf{gemm} (\tf{T}, \tf{M}, \tf{N}, $dots$) are chosen with respect to the tensor order $p$, layout $\mbpi$ of $\mubA$, $\mbB$, $\mubC$ and contraction mode $q$ where \tf{T} specifies if $\mbB$ is transposed.
Function \tf{gemm*} with a star denotes multiple \tf{gemm} calls with different tensor slices.
Argument $\bar{n}_q$ for case 6 and 7 is defined as $\bar{n}_q = (\prod_r^p n_r)/n_q$.
Input matrix $\mbB$ is either stored in the column-major or row-major format.
The storage format flag set for \tf{gemm} and \tf{gemv} is determined by the element ordering of $\mbB$.
}
\label{tab:mapping_rm_cm}
\end{table*}

BLAS-based algorithms for the TTM call CBLAS \ttt{gemm} function in the base case of Algorithm~\ref{alg:ttm.sequential.coalesced} in order to perform fast slice-matrix multiplications\footnote{CBLAS denotes the C interface to the BLAS.}.
Function \ttt{gemm} denotes a general matrix-matrix multiplication which is defined as \ttt{C:=a*op(A)*op(B)+b*C} where 
\ttt{a} and \ttt{b} are scalars, 
\ttt{A}, \ttt{B} and \ttt{C} are matrices,
\ttt{op(A)} is an \ttt{M}-by-\ttt{K} matrix, 
\ttt{op(B)} is a \ttt{K}-by-\ttt{N} matrix and 
\ttt{C} is an \ttt{N}-by-\ttt{N} matrix.
Function \ttt{op(x)} either transposes the corresponding matrix \ttt{x} such that \ttt{op(x)=x'} or not \ttt{op(x)=x}.
The CBLAS interface also allows users to specify matrix's leading dimension by providing the \ttt{LDA}, \ttt{LDB} and \ttt{LDC} parameters.
A leading dimension specifies the number of elements that is required for iterating over the non-contiguous matrix dimension.
The leading dimension can be used to perform a matrix multiplication with submatrices or even fibers within submatrices.
The leading dimension parameter is necessary for the BLAS-based TTM.

The eighth TTM case in Table~\ref{tab:mapping_rm_cm} contains all arguments that are necessary to perform a CBLAS \ttt{gemm} in the base case of Algorithm~\ref{alg:ttm.sequential.coalesced}.
The arguments of \ttt{gemm} are set according to the tensor order $p$, tensor layout $\mbpi$ and contraction mode $q$.
If the input matrix $\mbB$ has the row-major order, parameter \ttt{CBLAS\_ORDER} of function \ttt{gemm} is set to \ttt{CblasRowMajor} (\ttt{rm}) and \ttt{CblasColMajor} (\ttt{cm}) otherwise.
The eighth case will be denoted as the general case in which function \ttt{gemm} is called multiple times with different tensor slices.
Next to the eighth TTM case, there are seven corner cases where a single \ttt{gemv} or \ttt{gemm} call suffices to compute the tensor-matrix product.
For instance if $\pi_1 = q$, the tensor-matrix product can be computed by a matrix-matrix multiplication where the input tensor $\mubA$ can be reshaped and interpreted as a matrix without any copy operation.
%The same can be applied when $\pi_p = q$ and five other TTM cases where the input tensor is either one or two-dimensional.
Note that Table~\ref{tab:mapping_rm_cm} supports all linear tensor layouts of $\mubA$ and $\mubC$ with no limitations on tensor order and contraction mode.
The following subsection describes all eight TTM cases when the input matrix $\mbB$ has the row-major ordering.


\subsubsection{Row-Major Matrix Multiplication}
The following paragraphs introduce all TTM cases that are listed in Table~\ref{tab:mapping_rm_cm}.

\tit{Case 1:}
If $p=1$, The tensor-vector product $\mubA \times_1 \mbB$ can be computed with a \ttt{gemv} operation where $\mubA$ is an order-$1$ tensor $\mba$ of length $n_1$ such that $\mba^T \cdot \mbB$.

\tit{Case 2-5:}
If $p=2$, $\mubA$ and $\mubC$ are order-$2$ tensors with dimensions $n_1$ and $n_2$.
In this case the tensor-matrix product can be computed with a single \ttt{gemm}.
If $\mbA$ and $\mbC$ have the column-major format with $\mbpi=(1,2)$, \ttt{gemm} either executes $\mbC = \mbA \cdot \mbB^T$ for $q =1$ or $\mbC = \mbB \cdot \mbA$ for $q=2$.
Both matrices can be interpreted $\mbC$ and $\mbA$ as matrices in row-major format although both are stored column-wise.
If $\mbA$ and $\mbC$ have the row-major format with $\mbpi=(2,1)$, \ttt{gemm} either executes $\mbC = \mbB \cdot \mbA$ for $q =1$ or $\mbC = \mbA \cdot \mbB^T$ for $q=2$. 
The transposition of $\mbB$ is necessary for the TTM cases $2$ and $5$ which is independent of the chosen layout.

\tit{Case 6-7 :}
% If the order of $\mubA$ and $\mubC$ is greater than $2$ 
%the contraction mode $q$ is equal to $\pi_1$ 
If $p>2$ and if $q=\pi_1$(case 6), a single \ttt{gemm} with the corresponding arguments executes $\mbC = \mbA \cdot \mbB^T$ and computes a tensor-matrix product $\mubC = \mubA \times_{\pi_1} \mbB$.
% for any storage layout of $\mubA$ and $\mubC$
Tensors $\mubA$ and $\mubC$ are reshaped with $\varphi_{2,p}$ to row-major matrices $\mbA$ and $\mbC$.
%$f_{2,p}$, see subsection \ref{sec:preliminaries:flattening}.
Matrix $\mbA$ has $\bar{n}_{\pi_1} = \bar{n} / n_{\pi_1}$ rows and $n_{\pi_1}$ columns while matrix $\mbC$ has the same number of rows and $m$ columns.
If $\pi_p=q$ (case 7), $\mubA$ and $\mubC$ are reshaped with $\varphi_{1,p-1}$ to column-major matrices $\mbA$ and $\mbC$.
Matrix $\mbA$ has $n_{\pi_p}$ rows and $\bar{n}_{\pi_p} =  \bar{n} / n_{\pi_p}$ columns while $\mbC$ has $m$ rows and the same number of columns.
In this case, a single \ttt{gemm} executes $\mbC = \mbB \cdot \mbA$ and computes $\mubC = \mubA \times_{\pi_p} \mbB$.
Noticeably, the desired contraction are performed without copy operations, see also Section~\ref{sec:preliminaries:flattening.reshaping}. 

\tit{Case 8 $(p>2)$:}
If the tensor order is greater than $2$ with $\pi_1\neq q$ and $\pi_p \neq q$, the modified baseline Algorithm~\ref{alg:ttm.sequential.coalesced} is used to successively call $\bar{n} / (n_q \cdot n_{\pi_1})$ times \ttt{gemm} with different tensor slices of $\mubC$ and $\mubA$.
Each \ttt{gemm} computes one slice $\mubC_{\pi_1,q}'$ of the tensor-matrix product $\mubC$ using the corresponding tensor slices $\mubA_{\pi_1,q}'$ and the matrix $\mbB$.
The matrix-matrix product $\mbC = \mbB \cdot \mbA$ is performed by interpreting both tensor slices as row-major matrices $\mbA$ and $\mbC$ which have the dimensions $(n_q,n_{\pi_1})$ and $(m,n_{\pi_1})$, respectively.

\subsubsection{Column-Major Matrix Multiplication}
The tensor-matrix multiplication is performed with the column-major version of \ttt{gemm} when the input matrix $\mbB$ is stored in column-major order.
Although the number of \ttt{gemm} cases remains the same, the \ttt{gemm} arguments must be rearranged.
The argument arrangement for the column-major version can be derived from the row-major version that is provided in Table~\ref{tab:mapping_rm_cm}.

The CBLAS arguments of \ttt{M} and \ttt{N}, as well as \ttt{A} and \ttt{B} is swapped and the transposition flag for matrix $\mbB$ is toggled.
Also, the leading dimension argument of \ttt{A} is adjusted to \ttt{LDB} or \ttt{LDA}.
The only new argument is the new leading dimension of \ttt{B}.

Given case 4 with the row-major matrix multiplication in Table~\ref{tab:mapping_rm_cm} where tensor $\mubA$ and matrix $\mbB$ are passed to \ttt{B} and \ttt{A}.
The corresponding column-major version is attained when tensor $\mubA$ and matrix $\mbB$ are passed to \ttt{A} and \ttt{B} where the transpose flag for $\mbB$ is set and the remaining dimensions are adjusted accordingly.


\subsubsection{Matrix Multiplication Variations}
The column-major and row-major versions of \ttt{gemm} can be used interchangeably by adapting the storage format. 
This means that a \ttt{gemm} operation for column-major matrices can compute the same matrix product as one for row-major matrices, provided that the arguments are rearranged accordingly.
While the argument rearrangement is similar, the arguments associated with the matrices \ttt{A} and \ttt{B} must be interchanged.
Specifically, \ttt{LDA} and \ttt{LDB} as well as \ttt{M} and \ttt{N} are swapped along with the corresponding matrix pointers.
In addition, the transposition flag must be set for \ttt{A} or \ttt{B} in the new format if \ttt{B} or \ttt{A} is transposed in the original version.

For instance, the column-major matrix multiplication in case 4 of Table~\ref{tab:mapping_rm_cm} requires the arguments of \ttt{A} and \ttt{B} to be tensor $\mubA$ and matrix $\mbB$ with $\mbB$ being transposed.
The arguments of an equivalent row-major multiplication for \ttt{A}, \ttt{B}, \ttt{M}, \ttt{N}, \ttt{LDA}, \ttt{LDB} and \ttt{T} are then initialized with $\mbB$, $\mubA$, $m$, $n_2$, $m$, $n_2$ and $\mbB$.

Another possible matrix multiplication variant with the same product is computed when, instead of $\mbB$, tensors $\mubA$ and $\mubC$ with adjusted arguments are transposed.
We assume that such reformulations of the matrix multiplication do not outperform the variants shown in Table~\ref{tab:mapping_rm_cm}, as we expect BLAS libraries to have optimal blocking and multiplication strategies.


\subsection{Matrix Multiplication with Subtensors}
\label{sec:design:blas.based.algorithm.subtensors}
Algorithm~\ref{alg:ttm.sequential.coalesced} can be slightly modified in order to call \ttt{gemm} with reshaped order-$\mhq$ subtensors that correspond to larger tensor slices.
Given the contraction mode $q$ with $1 < q < p$, the maximum number of additionally fusible modes is $\mhq-1$ with $\mhq = \mbpi^{-1}(q)$ where $\mbpi^{-1}$ is the inverse layout tuple.
The corresponding fusible modes are therefore $\pi_1,\pi_2,\dots,\pi_{\mhq-1}$.

The non-base case of the modified algorithm only iterates over dimensions that have indices larger than $\mhq$ and thus omitting the first $\mhq$ modes.
The conditions in line 2 and 4 are changed to $1 < r \leq \mhq$ and $\mhq < r$, respectively.
Thus, loop indices belonging to the outer $\pi_r$-th loop with $\mhq+1 \leq r \leq p$ define the order-$\mhq$ subtensors $\mubA_{\mbpi'}'$ and $\mubC_{\mbpi'}'$ of $\mubA$ and $\mubC$ with $\mbpi' = (\pi_1,\dots,\pi_{\mhq-1},q)$.
Reshaping the subtensors $\mubA_{\mbpi'}'$ and $\mubC_{\mbpi'}'$ with $\varphi_{1,\mhq-1}$ for the modes $\pi_1,\dots,\pi_{\mhq-1}$ yields two tensor slices with dimension $n_q$ or $m$ with the fused dimension $\bar{n}_q = \prod_{r=1}^{\mhq-1} n_{\pi_r}$ and $\bar{n}_q = w_q$.
Both tensor slices can be interpreted either as row-major or column-major matrices with shapes $(n_q,\bar{n}_q)$ or $(w_q,\bar{n}_q)$ in case of $\mubA$ and $(m,\bar{n}_q)$ or $(\bar{n}_q,m)$ in case of $\mubC$, respectively.

The \ttt{gemm} function in the base case is called with almost identical arguments except for the parameter $M$ or $N$ which is set to $\bar{n}_q$ for a column-major or row-major multiplication, respectively.
Note that neither the selection of the subtensor nor the reshaping operation copy tensor elements.
This description supports all linear tensor layouts and generalizes lemma 4.2 in \cite{li:2015:input} without copying tensor elements, see section \ref{sec:preliminaries:flattening.reshaping}.
The division in large subtensors has also been described in \cite{ballard:2020:tuckermpi} for tensors with a first-order layout.
 
\subsection{Parallel BLAS-based Algorithms}
\label{subsec:parallel.multi-loops}
Most BLAS libraries provide an option to change the number of threads.
Hence, functions such as \ttt{gemm} and \ttt{gemv} can be run either using a single or multiple threads.
The TTM cases one to seven contain a single BLAS call which is why we set the number of threads to the number of available cores.
The following subsections discuss parallel versions for the eighth case in which the outer loops of Algorithm~\ref{alg:ttm.sequential.coalesced} and the \ttt{gemm} function inside the base case can be run in parallel.
Note that the parallelization strategies can be combined with the aforementioned slicing methods.

\subsubsection{Sequential Loops and Parallel Matrix Multiplication}
Algorithm~\ref{alg:ttm.sequential.coalesced} is run for the eighth case and does not need to be modified except for  enabling \ttt{gemm} to run multi-threaded in the base case.
This type of parallelization strategy might be beneficial with order-$\mhq$ subtensors where the contraction mode satisfies $q = \pi_{p-1}$, the inner dimensions $n_{\pi_1},\dots,n_{\mhq}$ are large and the outer-most dimension $n_{\pi_{p}}$ is smaller than the available processor cores.
For instance, given a first-order storage format and the contraction mode $q$ with $q=p-1$ and $n_p=2$, the dimensions of reshaped order-$q$ subtensors are $\prod_{r=1}^{p-2}n_r$ and $n_{p-1}$.
This allows \ttt{gemm} to perform with large dimensions using multiple threads increasing the likelihood to reach a high throughput.
However, if the above conditions are not met, a multi-threaded \ttt{gemm} operates on small tensor slices which might lead to an suboptimal utilization of the available cores.
This algorithm version will be referred to as \ttt{<par-gemm>}.
Depending on the subtensor shape, we will either add \ttt{<slice>} for order-$2$ subtensors or \ttt{<subtensor>} for order-$\mhq$ subtensors with $\mhq = \pi^{-1}_q$.

\begin{algorithm}[t]
\footnotesize
\DontPrintSemicolon
\SetAlgoVlined
\SetKwProg{Fn}{}{}{end}
\SetKwFunction{Func}{ttm<par-loop><slice>}%
\SetKwFunction{GEMM}{gemm}%
\SetKwFunction{reshape}{reshape}%
\SetKw{KwWith}{with}
\SetKw{KwStep}{step}
\SetKw{KwThreads}{threads}
\SetKwFor{ParallelFor}{parallel for}{do}{endfor}
\hrule
\BlankLine
%\Fn{\Func{$\mubA'$, $\mubA'$$\mubC'$, $$ $\mbn'$, $\mbw'$, $m$}}
\Fn{\Func{$\mubA$, $\mbB$, $\mubC$, $\mbn$, $\mbpi$, $m$, $q$, $p$}}
{
	%[$\mubA'$,$\mbn'$,$\mbw'$] $=$ \reshape($\mubA$, $\mbn$, $\mbpi$, $q$, $p$)\;
	%[$\mubC'$,\_,\_] $=$ \reshape($\mubC$, $\mbm$, $\mbpi$, $q$, $p$)\;
	%[$\mbn'$,$\mbw'$] $=$ \reshape($\mbn$, $\mbpi$, $q$, $p$)\;
	[$\mubA'$, $\mubC'$, $\mbn'$, $\mbw'$] $=$ \reshape($\mubA$, $\mubC$, $\mbn$, $m$, $\mbpi$, $q$, $p$)\;
	\ParallelFor{$i \leftarrow 1$ \KwTo $n_{4}'$}
	{
		\ParallelFor{$j \leftarrow 1$ \KwTo $n_{2}'$}
		{
			\GEMM{$m$, $n_{1}'$, $n_{3}'$, $1$, $\mbB$,$n_{3}'$, $\mubA_{ij}'$,$w_{3}'$, $0$, $\mubC_{ij}'$,$w_{3}'$}\;
		}
	}
}
\BlankLine
\hrule
\caption{%
\footnotesize
Function \tf{ttm<par-loop><slice>} is an optimized version of Algorithm~\ref{alg:ttm.sequential.coalesced}.
The \tf{reshape} function transforms the order-$p$ tensors $\mubA$ and $\mubC$ with layout tuple $\mbpi$ and their respective dimension tuples $\mbn$ and $\mbm$ into order-$4$ tensors $\mubA'$ and $\mubC'$ with layout tuple $\mbpi'$ and their respective dimension tuples $\mbn'$ and $\mbm'$ where $\mbn' = (n_{\pi_1},\mhn_{\pi_2},n_q,\mhn_{\pi_4})$ and $m_3' = m$ and $n_k' = m_k'$ for $k \neq 3$.
Each thread calls multiple single-threaded \tf{gemm} functions each of which executes a slice-matrix multiplication with the order-$2$ tensor slices $\mubA_{ij}'$ and $\mubC_{ij}'$.
Matrix $\mbB$ has the row-major storage format.
\label{alg:ttm.slice.fused.parallel}
}
\end{algorithm}


\subsubsection{Parallel Loops and Sequential Matrix Multiplication}
Instead of sequentially calling multi-threaded \ttt{gemm}, it is also possible to call single-threaded \ttt{gemm}s in parallel.
Similar to the previous approach, the matrix multiplication can be performed with tensor slices or order-$\mhq$ subtensors.

\paragraph{Matrix Multiplication with Tensor Slices}
Algorithm~\ref{alg:ttm.slice.fused.parallel} with function \ttt{ttm}\ttt{<par-loop>}\allowbreak\ttt{<slice>} executes a single-threaded \ttt{gemm} with tensor slices in parallel using all modes except $\pi_1$ and $\pi_{\mhq}$.
The first statement of the algorithm calls the \ttt{reshape} function which transforms tensors $\mubA$ and $\mubC$ without copying elements by calling the reshaping operation $\varphi_{\pi_{\mhq+1},\pi_p}$ and $\varphi_{\pi_{2},\pi_{\mhq-1}}$.
The resulting tensors $\mubA'$ and $\mubC'$ are of order $4$.
Tensor $\mubA'$ has the shape $\mbn'=(n_{\pi_1},\mhn_{\pi_2},n_{q}, \mhn_{\pi_4})$ with the dimensions $\mhn_{\pi_2} = \prod_{r=2}^{\mhq-1} n_{\pi_r}$ and $\mhn_{\pi_4} = \prod_{r=\mhq+1}^{p} n_{\pi_r}$.
Tensor $\mubC'$ has the same shape as $\mubA'$ with dimensions $m_r' = n_r'$ except for the third dimension which is given by $m_3=m$.

The following two \ttt{parallel for} loops iterate over all free modes.
The outer loop iterates over $n_4' = \mhn_{\pi_4}$ while the inner one loops over $n_2' = \mhn_{\pi_2}$ calling \ttt{gemm} with tensor slices $\mubA_{2,4}'$ and $\mubC_{2,4}'$.
Here, we assume that matrix $\mbB$ has the row-major format which is why both tensor slices are also treated as row-major matrices.
Notice that \ttt{gemm} in Algorithm~\ref{alg:ttm.slice.fused.parallel} will be called with exact same arguments as displayed in the eighth case in Table~\ref{tab:mapping_rm_cm} where $n_{1}' = n_{\pi_1}$, $n_{3}' = n_q$ and $w_q = w_3'$. %$w_q = \prod_{r=1}^{\mhq-1} n_{\pi_r} = w_3' = n_{\pi_1} \cdot \mhn_{\pi_2} = \prod_{r=1}^{\mhq-1} n_{\pi_r}$
For the sake of simplicity, we omitted the first three arguments of \ttt{gemm} which are set to \ttt{CblasRowMajor} and \ttt{CblasNoTrans} for \ttt{A} and \ttt{B}.
With the help of the reshaping operation, the tree-recursion has been transformed into two loops which iterate over all free indices.



\paragraph{Matrix Multiplication with Subtensors}
An alternative algorithm is given by combining Algorithm~\ref{alg:ttm.slice.fused.parallel} with order-$\mhq$ subtensors that have been discussed in \ref{sec:design:blas.based.algorithm.subtensors}.
With order-$\mhq$ subtensors, only the outer modes $\pi_{\mhq+1},\dots,\pi_{p}$ are free for parallel execution while the inner modes $\pi_{1},\dots,\pi_{\mhq-1},q$ are used for the slice-matrix multiplication.
Therefore, both tensors are reshaped twice using $\varphi_{\pi_{1},\pi_{\mhq-1}}$ and $\varphi_{\pi_{\mhq+1},\pi_p}$. 
Note that in contrast to tensor slices, the first reshaping also contains the dimension $n_{\pi_{1}}$.
The reshaped tensors are of order $3$ where $\mubA'$ has the shape $\mbn'=(\mhn_{\pi_1},n_{q},\mhn_{\pi_3})$ with $\mhn_{\pi_1} = \prod_{r=1}^{\mhq-1} n_{\pi_r}$ and $\mhn_{\pi_3} = \prod_{r=\mhq+1}^{p} n_{\pi_r}$.
Tensor $\mubC'$ has the same dimensions as $\mubA'$ except for $m_2=m$.

Algorithm~\ref{alg:ttm.slice.fused.parallel} needs a minor modification for supporting order-$\mhq$ subtensors.
Instead of two loops, the modified algorithm consists of a single loop which iterates over dimension $\mhn_{\pi_3}$ calling a single-threaded \ttt{gemm} with subtensors $\mubA'$ and $\mubC'$.
The shape and strides of both subtensors as well as the function arguments of \ttt{gemm} have already been provided by the previous Section~\ref{sec:design:blas.based.algorithm.subtensors}.
This \ttt{ttm} version will referred to as \ttt{<par-loop>}\allowbreak\ttt{<subtensor>}.

Note that functions \ttt{<par-gemm>} and \ttt{<par-loop>} implement opposing versions of the \ttt{ttm} where either \ttt{gemm} or the fused loop is performed in parallel.
Version \ttt{<par-loop-gemm} executes available loops in parallel where each loop thread executes a multi-threaded \ttt{gemm} with either subtensors or tensor slices.


\subsubsection{Combined Matrix Multiplication}
The combined matrix multiplication calls one of the previously discussed functions depending on the number of available cores.
The heuristic assumes that function \ttt{<par-gemm>} is not able to efficiently utilize the processor cores if subtensors or tensor slices are too small.
The corresponding algorithm switches between \ttt{<par-loop>} and \ttt{<par-gemm>} with subtensors by first calculating the parallel and combined loop count $\mhn = \prod_{r=1}^{\mhq-1} n_{\pi_r}$ and $\mhn' = \prod_{r=1}^{p} n_{\pi_r} / n_q$, respectively.
Given the number of physical processor cores as \ttt{ncores}, the algorithm executes \ttt{<par-loop>} with \ttt{<subtensor>} if \ttt{ncores} is greater than or equal to $\mhn$ and call \ttt{<par-loop>} with \ttt{<slice>} if \ttt{ncores} is greater than or equal to $\mhn'$.
Otherwise, the algorithm will default to \ttt{<par-gemm>} with \ttt{<subtensor>}.
Function \ttt{par-gemm} with tensor slices is not used here.
The presented strategy is different to the one presented in \cite{li:2015:input} that maximizes the number of modes involved in the matrix multiply.
We will refer to this version as \ttt{<combined>} to denote a selected combination of \ttt{<par-loop>} and \ttt{<par-gemm>} functions.

\subsubsection{Multithreaded Batched Matrix Multiplication}
The multithreaded batched matrix multiplication version calls in the eighth case a single \ttt{gemm\_batch} function that is provided by Intel MKL's BLAS-like extension.
With an interface that is similar to the one of \ttt{cblas\_gemm}, function \ttt{gemm\_batch} performs a series of matrix-matrix operations with general matrices.
All parameters except \ttt{CBLAS\_LAYOUT} requires an array as an argument which is why different subtensors of the same corresponding tensors are passed to \ttt{gemm\_batch}.
The subtensor dimensions and remaining \ttt{gemm} arguments are replicated within the corresponding arrays.
Note that the MKL is responsible of how subtensor-matrix multiplications are executed and whether subtensors are further divided into smaller subtensors or tensor slices.
This algorithm will be referred to as \ttt{<batched-gemm>}.
